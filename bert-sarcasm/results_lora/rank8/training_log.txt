=== Training Log ===

Base model metrics: {'eval_loss': 0.7509651780128479, 'eval_model_preparation_time': 0.0012, 'eval_accuracy': 0.5214659685863874, 'eval_f1': 0.017204301075268817, 'eval_runtime': 13.5412, 'eval_samples_per_second': 70.526, 'eval_steps_per_second': 4.431}

Applying LoRA adapters...
LoRA configuration: rank=8, alpha=16, dropout=0.1, bias=none
Step 10: loss = 0.7899
Step 20: loss = 0.7299
Step 30: loss = 0.7149
Step 40: loss = 0.7176
Step 50: loss = 0.7039
Step 60: loss = 0.7114
Step 70: loss = 0.6976
Step 80: loss = 0.6822
Step 90: loss = 0.7051
Step 100: loss = 0.7056
Step 110: loss = 0.6981
Step 120: loss = 0.7030
Step 130: loss = 0.6904
Step 140: loss = 0.7010
Step 150: loss = 0.6962
Step 160: loss = 0.7149
Step 170: loss = 0.6849
Step 180: loss = 0.6821
Step 190: loss = 0.6995
Step 200: loss = 0.7089
Step 210: loss = 0.7041
Step 220: loss = 0.6914
Step 230: loss = 0.7007
Step 240: loss = 0.6812
Step 250: loss = 0.6910
Step 260: loss = 0.6939
Step 270: loss = 0.6915
Step 280: loss = 0.6925
Step 290: loss = 0.6996
Step 300: loss = 0.6884
Step 310: loss = 0.6968
Step 320: loss = 0.6874
Step 330: loss = 0.7113
Step 340: loss = 0.6847
Step 350: loss = 0.7017
Step 360: loss = 0.6951
Step 370: loss = 0.6853
Step 380: loss = 0.6833
Step 390: loss = 0.6880
Step 400: loss = 0.6937
Step 410: loss = 0.6952
Step 420: loss = 0.6958
Step 430: loss = 0.6933
Step 440: loss = 0.6978
Step 450: loss = 0.6832
Step 460: loss = 0.6855
Step 470: loss = 0.6955
Step 480: loss = 0.6986
Step 490: loss = 0.6882
Step 500: loss = 0.6918
Step 510: loss = 0.7001
Step 520: loss = 0.6950
Step 530: loss = 0.6913
Final metrics: {'eval_loss': 0.6887720227241516, 'eval_accuracy': 0.5591623036649215, 'eval_f1': 0.5690890481064483, 'eval_runtime': 15.3233, 'eval_samples_per_second': 62.323, 'eval_steps_per_second': 3.916, 'epoch': 3.0}
